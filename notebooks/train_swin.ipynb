{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Swin Transformer Training Notebook (Kaggle Version)\n",
                "\n",
                "This notebook trains a **Swin Transformer** model for Face Recognition.\n",
                "It uses `timm` for easy model creation and is optimized for Kaggle.\n",
                "\n",
                "**Prerequisite:** Upload your `data_processed` folder as a Kaggle Dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "import numpy as np\n",
                "from tqdm.notebook import tqdm\n",
                "import sys\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# ==========================================\n",
                "# KAGGLE SETUP\n",
                "# ==========================================\n",
                "# Install dependencies (Clean & Simple!)\n",
                "!pip install -q timm albumentations scikit-learn\n",
                "\n",
                "import timm\n",
                "print(f\"‚úÖ timm version: {timm.__version__}\")\n",
                "\n",
                "# Check GPU\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"‚úÖ GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Warning: No GPU detected. Training will be slow.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# INLINE UTILS (Dataset & Augmentations)\n",
                "# ==========================================\n",
                "import cv2\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "from torch.utils.data import Dataset\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import confusion_matrix, classification_report\n",
                "\n",
                "class FaceDataset(Dataset):\n",
                "    def __init__(self, images, labels, transform=None):\n",
                "        self.images = images\n",
                "        self.labels = labels\n",
                "        self.transform = transform\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.images)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        image = self.images[idx]\n",
                "        label = self.labels[idx]\n",
                "        if image.dtype != np.uint8:\n",
                "            image = image.astype(np.uint8)\n",
                "        if self.transform:\n",
                "            augmented = self.transform(image=image)\n",
                "            image = augmented['image']\n",
                "        else:\n",
                "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
                "        return image, torch.tensor(label, dtype=torch.long)\n",
                "\n",
                "# Augmentations\n",
                "train_transforms = A.Compose([\n",
                "    A.HorizontalFlip(p=0.5),\n",
                "    A.Rotate(limit=15, p=0.5),\n",
                "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
                "    A.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), p=0.5),\n",
                "    A.GaussianBlur(blur_limit=3, p=0.2),\n",
                "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
                "    ToTensorV2()\n",
                "])\n",
                "\n",
                "test_transforms = A.Compose([\n",
                "    A.Resize(224, 224),\n",
                "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
                "    ToTensorV2()\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# DATA LOADING\n",
                "# ==========================================\n",
                "# GANTI 'face-recognition-data' DENGAN NAMA DATASET ANDA DI KAGGLE\n",
                "DATA_DIR = \"/kaggle/input/face-recognition-data/data_processed\"\n",
                "TARGET_SIZE = (224, 224)\n",
                "\n",
                "def load_dataset_kaggle():\n",
                "    X = []\n",
                "    y = []\n",
                "    label_map = {}\n",
                "    \n",
                "    if not os.path.exists(DATA_DIR):\n",
                "        print(f\"‚ùå Error: Path {DATA_DIR} tidak ditemukan.\")\n",
                "        print(\"Pastikan Anda sudah Add Data di sidebar kanan Kaggle.\")\n",
                "        return [], [], {}\n",
                "\n",
                "    folders = sorted(os.listdir(DATA_DIR))\n",
                "    for idx, folder in enumerate(folders):\n",
                "        label_map[folder] = idx\n",
                "        folder_path = os.path.join(DATA_DIR, folder)\n",
                "\n",
                "        for filename in os.listdir(folder_path):\n",
                "            if filename.lower().endswith((\".jpg\", \".png\", \".jpeg\", \".webp\")):\n",
                "                img_path = os.path.join(folder_path, filename)\n",
                "                img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
                "                img = cv2.resize(img, TARGET_SIZE)\n",
                "                X.append(img)\n",
                "                y.append(idx)\n",
                "\n",
                "    X = np.array(X)\n",
                "    y = np.array(y)\n",
                "    print(f\"üì¶ Loaded {len(X)} images from {len(label_map)} classes.\")\n",
                "    return X, y, label_map\n",
                "\n",
                "def split_dataset(X, y):\n",
                "    try:\n",
                "        # Try stratified split first\n",
                "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
                "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=42)\n",
                "    except ValueError as e:\n",
                "        print(f\"‚ö†Ô∏è Warning: Stratified split failed. Falling back to random split.\")\n",
                "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
                "        \n",
                "    return X_train, X_val, X_test, y_train, y_val, y_test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8bbeab23",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# CONFIGURATION (HYPERPARAMETERS)\n",
                "# ==========================================\n",
                "# üõ†Ô∏è GANTI NILAI DI SINI UNTUK EKSPERIMEN\n",
                "CONFIG = {\n",
                "    'BATCH_SIZE': 32,          # Jumlah gambar per batch (turunkan jika OOM)\n",
                "    'EPOCHS': 20,              # Jumlah epoch training\n",
                "    'LEARNING_RATE': 1e-4,     # Kecepatan belajar (1e-4 = 0.0001)\n",
                "    'WEIGHT_DECAY': 0.05,      # Regularisasi untuk mencegah overfitting\n",
                "    'IMAGE_SIZE': 224,         # Ukuran input gambar (Swin Tiny pakai 224)\n",
                "    'NUM_WORKERS': 2,          # Jumlah worker dataloader\n",
                "    'SEED': 42,                # Seed untuk reproducibility\n",
                "    'CHECKPOINT_DIR': \"/kaggle/working/checkpoints\",\n",
                "    'EARLY_STOPPING_PATIENCE': 5 # Stop jika loss tidak turun selama 5 epoch\n",
                "}\n",
                "\n",
                "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "os.makedirs(CONFIG['CHECKPOINT_DIR'], exist_ok=True)\n",
                "\n",
                "print(\"‚öôÔ∏è Configuration:\")\n",
                "for key, val in CONFIG.items():\n",
                "    print(f\"   {key}: {val}\")\n",
                "\n",
                "def create_swin_model(num_classes):\n",
                "    print(\"ü¶¢ Creating Swin Transformer Model...\")\n",
                "    # Using 'swin_tiny_patch4_window7_224' - A great balance of speed and accuracy\n",
                "    model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=num_classes)\n",
                "    return model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "06f2a489",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# TRAINING HELPERS\n",
                "# ==========================================\n",
                "def train_one_epoch(model, loader, criterion, optimizer, epoch):\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{CONFIG['EPOCHS']} [Train]\")\n",
                "    for images, labels in pbar:\n",
                "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        running_loss += loss.item()\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "        pbar.set_postfix({'loss': running_loss/total, 'acc': 100 * correct / total})\n",
                "    return running_loss / len(loader), 100 * correct / total\n",
                "\n",
                "def validate(model, loader, criterion, epoch):\n",
                "    model.eval()\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    with torch.no_grad():\n",
                "        pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{CONFIG['EPOCHS']} [Val]\")\n",
                "        for images, labels in pbar:\n",
                "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            running_loss += loss.item()\n",
                "            _, predicted = torch.max(outputs.data, 1)\n",
                "            total += labels.size(0)\n",
                "            correct += (predicted == labels).sum().item()\n",
                "            pbar.set_postfix({'loss': running_loss/total, 'acc': 100 * correct / total})\n",
                "    return running_loss / len(loader), 100 * correct / total"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a9073442",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# EXECUTION\n",
                "# ==========================================\n",
                "print(\"üöÄ Starting Swin Transformer Training...\")\n",
                "\n",
                "# 1. Load Data\n",
                "X, y, label_map = load_dataset_kaggle()\n",
                "\n",
                "if len(X) > 0:\n",
                "    num_classes = len(label_map)\n",
                "    print(f\"‚úÖ Detected {num_classes} classes.\")\n",
                "\n",
                "    # 2. Split\n",
                "    X_train, X_val, X_test, y_train, y_val, y_test = split_dataset(X, y)\n",
                "\n",
                "    # 3. Dataloaders\n",
                "    train_dataset = FaceDataset(X_train, y_train, transform=train_transforms)\n",
                "    val_dataset = FaceDataset(X_val, y_val, transform=test_transforms)\n",
                "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True, num_workers=CONFIG['NUM_WORKERS'])\n",
                "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False, num_workers=CONFIG['NUM_WORKERS'])\n",
                "\n",
                "    # 4. Model\n",
                "    model = create_swin_model(num_classes).to(DEVICE)\n",
                "\n",
                "    # 5. Train\n",
                "    criterion = nn.CrossEntropyLoss()\n",
                "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['LEARNING_RATE'], weight_decay=CONFIG['WEIGHT_DECAY'])\n",
                "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['EPOCHS'])\n",
                "\n",
                "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
                "    best_acc = 0.0\n",
                "    best_loss = float('inf')\n",
                "    patience_counter = 0\n",
                "    \n",
                "    for epoch in range(CONFIG['EPOCHS']):\n",
                "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
                "        val_loss, val_acc = validate(model, val_loader, criterion, epoch)\n",
                "        scheduler.step()\n",
                "        \n",
                "        # Store history\n",
                "        history['train_loss'].append(train_loss)\n",
                "        history['train_acc'].append(train_acc)\n",
                "        history['val_loss'].append(val_loss)\n",
                "        history['val_acc'].append(val_acc)\n",
                "        \n",
                "        print(f\"Summary: Train Loss {train_loss:.4f} | Val Acc {val_acc:.2f}%\")\n",
                "        \n",
                "        # Save Best Model (Based on Accuracy)\n",
                "        if val_acc > best_acc:\n",
                "            best_acc = val_acc\n",
                "            torch.save(model.state_dict(), os.path.join(CONFIG['CHECKPOINT_DIR'], \"swin_best.pth\"))\n",
                "            print(\"üíæ Saved Best Model (Best Accuracy)\")\n",
                "            \n",
                "        # Early Stopping Logic (Based on Loss)\n",
                "        if val_loss < best_loss:\n",
                "            best_loss = val_loss\n",
                "            patience_counter = 0\n",
                "        else:\n",
                "            patience_counter += 1\n",
                "            print(f\"‚ö†Ô∏è Early Stopping Counter: {patience_counter}/{CONFIG['EARLY_STOPPING_PATIENCE']}\")\n",
                "            \n",
                "        if patience_counter >= CONFIG['EARLY_STOPPING_PATIENCE']:\n",
                "            print(\"üõë Early Stopping Triggered! Validation loss stopped improving.\")\n",
                "            break\n",
                "            \n",
                "    # ==========================================\n",
                "    # VISUALIZATION & METRICS\n",
                "    # ==========================================\n",
                "    # A. Plot Loss & Accuracy\n",
                "    plt.figure(figsize=(12, 5))\n",
                "\n",
                "    # Loss\n",
                "    plt.subplot(1, 2, 1)\n",
                "    plt.plot(history['train_loss'], label='Train Loss')\n",
                "    plt.plot(history['val_loss'], label='Val Loss')\n",
                "    plt.title('Loss History')\n",
                "    plt.xlabel('Epoch')\n",
                "    plt.ylabel('Loss')\n",
                "    plt.legend()\n",
                "\n",
                "    # Accuracy\n",
                "    plt.subplot(1, 2, 2)\n",
                "    plt.plot(history['train_acc'], label='Train Acc')\n",
                "    plt.plot(history['val_acc'], label='Val Acc')\n",
                "    plt.title('Accuracy History')\n",
                "    plt.xlabel('Epoch')\n",
                "    plt.ylabel('Accuracy (%)')\n",
                "    plt.legend()\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(os.path.join(CONFIG['CHECKPOINT_DIR'], 'training_history.png'))\n",
                "    plt.show()\n",
                "\n",
                "    # B. Top-K Accuracy (Better for many classes)\n",
                "    print(\"üîç Calculating Top-1 and Top-5 Accuracy...\")\n",
                "    model.load_state_dict(torch.load(os.path.join(CONFIG['CHECKPOINT_DIR'], \"swin_best.pth\")))\n",
                "    model.eval()\n",
                "\n",
                "    correct_1 = 0\n",
                "    correct_5 = 0\n",
                "    total = 0\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for images, labels in val_loader:\n",
                "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
                "            outputs = model(images)\n",
                "            \n",
                "            # Top-1\n",
                "            _, pred_1 = outputs.topk(1, 1, True, True)\n",
                "            pred_1 = pred_1.t()\n",
                "            correct_1 += pred_1.eq(labels.view(1, -1).expand_as(pred_1)).sum().item()\n",
                "            \n",
                "            # Top-5\n",
                "            max_k = min(5, num_classes) # Handle if classes < 5\n",
                "            _, pred_5 = outputs.topk(max_k, 1, True, True)\n",
                "            pred_5 = pred_5.t()\n",
                "            correct_5 += pred_5.eq(labels.view(1, -1).expand_as(pred_5)).sum().item()\n",
                "            \n",
                "            total += labels.size(0)\n",
                "\n",
                "    acc_1 = 100 * correct_1 / total\n",
                "    acc_5 = 100 * correct_5 / total\n",
                "    print(f\"\\nüèÜ Final Test Results:\")\n",
                "    print(f\"   Top-1 Accuracy: {acc_1:.2f}%\")\n",
                "    print(f\"   Top-5 Accuracy: {acc_5:.2f}%\")\n",
                "\n",
                "    # C. Visualize Predictions (5 Random Images)\n",
                "    print(\"\\nüñºÔ∏è Visualizing Predictions...\")\n",
                "    \n",
                "    # Get a batch\n",
                "    dataiter = iter(val_loader)\n",
                "    images, labels = next(dataiter)\n",
                "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
                "    \n",
                "    # Predict\n",
                "    outputs = model(images)\n",
                "    _, preds = torch.max(outputs, 1)\n",
                "    \n",
                "    # Select 5 random indices\n",
                "    indices = np.random.choice(len(images), 5, replace=False)\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
                "    \n",
                "    # Inverse Normalize for display\n",
                "    mean = torch.tensor([0.485, 0.456, 0.406]).to(DEVICE).view(3, 1, 1)\n",
                "    std = torch.tensor([0.229, 0.224, 0.225]).to(DEVICE).view(3, 1, 1)\n",
                "    \n",
                "    idx_to_class = {v: k for k, v in label_map.items()}\n",
                "\n",
                "    for i, idx in enumerate(indices):\n",
                "        img = images[idx]\n",
                "        # Un-normalize\n",
                "        img = img * std + mean\n",
                "        img = torch.clamp(img, 0, 1)\n",
                "        img = img.permute(1, 2, 0).cpu().numpy()\n",
                "        \n",
                "        true_label = idx_to_class[labels[idx].item()]\n",
                "        pred_label = idx_to_class[preds[idx].item()]\n",
                "        \n",
                "        color = 'green' if true_label == pred_label else 'red'\n",
                "        \n",
                "        axes[i].imshow(img)\n",
                "        axes[i].set_title(f\"True: {true_label}\\nPred: {pred_label}\", color=color)\n",
                "        axes[i].axis('off')\n",
                "        \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(os.path.join(CONFIG['CHECKPOINT_DIR'], 'prediction_samples.png'))\n",
                "    plt.show()\n",
                "\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No data found. Please check dataset path.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
