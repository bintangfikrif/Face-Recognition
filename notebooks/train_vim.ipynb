{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Vision Mamba Training Notebook\n",
                "\n",
                "This notebook allows you to train the Vision Mamba (Vim) model for Face Recognition step-by-step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "import numpy as np\n",
                "from tqdm.notebook import tqdm\n",
                "import sys\n",
                "\n",
                "# Tambahkan path lokal agar bisa import utils\n",
                "sys.path.append(os.path.abspath('..')) # Asumsi notebook ada di folder 'notebooks'\n",
                "\n",
                "from utils.dataloader import load_dataset, split_dataset\n",
                "from utils.dataset import FaceDataset\n",
                "from utils.augmentations import train_transforms, test_transforms"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# KONFIGURASI\n",
                "# ==========================================\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 20\n",
                "LEARNING_RATE = 1e-4\n",
                "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "CHECKPOINT_DIR = \"../checkpoints\"\n",
                "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
                "\n",
                "print(f\"Device: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# SETUP MODEL (VISION MAMBA)\n",
                "# ==========================================\n",
                "def create_vim_model(num_classes):\n",
                "    \"\"\"\n",
                "    Membuat model Vision Mamba.\n",
                "    Asumsi: Repo 'Vim' sudah di-clone di Colab.\n",
                "    \"\"\"\n",
                "    try:\n",
                "        # Import dari repo Vim yang di-clone\n",
                "        # Pastikan folder 'Vim' ada di path atau di-clone\n",
                "        from vim.models_mamba import VisionMamba\n",
                "        \n",
                "        print(\"üêç Menggunakan Vision Mamba (Vim) Model...\")\n",
                "        \n",
                "        # Konfigurasi standar Vim-Tiny atau Vim-Small (sesuaikan dengan VRAM)\n",
                "        model = VisionMamba(\n",
                "            img_size=224, \n",
                "            patch_size=16, \n",
                "            embed_dim=192,  # Vim-Tiny\n",
                "            depth=24, \n",
                "            rms_norm=True, \n",
                "            residual_in_fp32=True, \n",
                "            fused_add_norm=True, \n",
                "            final_pool_type='mean', \n",
                "            if_abs_pos_embed=True, \n",
                "            if_rope=False, \n",
                "            if_rope_residual=False, \n",
                "            bimamba_type=\"v2\", \n",
                "            if_cls_token=True, \n",
                "            if_devide_out=True, \n",
                "            use_middle_cls_token=True,\n",
                "            num_classes=num_classes\n",
                "        )\n",
                "        return model\n",
                "    except ImportError:\n",
                "        print(\"‚ùå Error: Library 'vim' tidak ditemukan.\")\n",
                "        print(\"Pastikan Anda sudah clone repo Vim: 'git clone https://github.com/hustvl/Vim.git'\")\n",
                "        print(\"Dan install requirements-nya.\")\n",
                "        # sys.exit(1) # Tidak exit di notebook"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# TRAINING LOOP\n",
                "# ==========================================\n",
                "def train_one_epoch(model, loader, criterion, optimizer, epoch):\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")\n",
                "    for images, labels in pbar:\n",
                "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        running_loss += loss.item()\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "        \n",
                "        pbar.set_postfix({'loss': running_loss/total, 'acc': 100 * correct / total})\n",
                "        \n",
                "    return running_loss / len(loader), 100 * correct / total\n",
                "\n",
                "def validate(model, loader, criterion, epoch):\n",
                "    model.eval()\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\")\n",
                "        for images, labels in pbar:\n",
                "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
                "            \n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            \n",
                "            running_loss += loss.item()\n",
                "            _, predicted = torch.max(outputs.data, 1)\n",
                "            total += labels.size(0)\n",
                "            correct += (predicted == labels).sum().item()\n",
                "            \n",
                "            pbar.set_postfix({'loss': running_loss/total, 'acc': 100 * correct / total})\n",
                "            \n",
                "    return running_loss / len(loader), 100 * correct / total"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Load Data\n",
                "print(\"üìÇ Loading Dataset...\")\n",
                "# Perlu sesuaikan path DATA_DIR di dataloader.py jika dijalankan dari notebooks/\n",
                "# Atau kita set working directory ke root project dulu\n",
                "if os.path.basename(os.getcwd()) == 'notebooks':\n",
                "    os.chdir('..')\n",
                "    print(f\"Changed working directory to: {os.getcwd()}\")\n",
                "\n",
                "X, y, label_map = load_dataset()\n",
                "num_classes = len(label_map)\n",
                "print(f\"‚úÖ Detected {num_classes} classes.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Split Data\n",
                "X_train, X_val, X_test, y_train, y_val, y_test = split_dataset(X, y)\n",
                "\n",
                "# 3. Create Datasets & Dataloaders\n",
                "train_dataset = FaceDataset(X_train, y_train, transform=train_transforms)\n",
                "val_dataset = FaceDataset(X_val, y_val, transform=test_transforms)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
                "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Initialize Model\n",
                "model = create_vim_model(num_classes).to(DEVICE)\n",
                "\n",
                "# 5. Loss & Optimizer\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.05)\n",
                "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b775b3b7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Training Loop\n",
                "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
                "best_acc = 0.0\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
                "    val_loss, val_acc = validate(model, val_loader, criterion, epoch)\n",
                "    \n",
                "    scheduler.step()\n",
                "    \n",
                "    # Store history\n",
                "    history['train_loss'].append(train_loss)\n",
                "    history['train_acc'].append(train_acc)\n",
                "    history['val_loss'].append(val_loss)\n",
                "    history['val_acc'].append(val_acc)\n",
                "    \n",
                "    print(f\"üìä Epoch {epoch+1} Summary:\")\n",
                "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
                "    print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
                "    \n",
                "    # Save Best Model\n",
                "    if val_acc > best_acc:\n",
                "        best_acc = val_acc\n",
                "        save_path = os.path.join(CHECKPOINT_DIR, \"vim_best.pth\")\n",
                "        torch.save(model.state_dict(), save_path)\n",
                "        print(f\"üíæ Model saved to {save_path}\")\n",
                "        \n",
                "print(\"üéâ Training Completed!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7556b38d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# VISUALIZATION & METRICS\n",
                "# ==========================================\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import confusion_matrix, classification_report\n",
                "\n",
                "# A. Plot Loss & Accuracy\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "# Loss\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history['train_loss'], label='Train Loss')\n",
                "plt.plot(history['val_loss'], label='Val Loss')\n",
                "plt.title('Loss History')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "\n",
                "# Accuracy\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history['train_acc'], label='Train Acc')\n",
                "plt.plot(history['val_acc'], label='Val Acc')\n",
                "plt.title('Accuracy History')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Accuracy (%)')\n",
                "plt.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(CHECKPOINT_DIR, 'training_history.png'))\n",
                "plt.show()\n",
                "\n",
                "# B. Confusion Matrix\n",
                "print(\"üîç Generating Confusion Matrix...\")\n",
                "model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, \"vim_best.pth\")))\n",
                "model.eval()\n",
                "\n",
                "all_preds = []\n",
                "all_labels = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for images, labels in val_loader:\n",
                "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
                "        outputs = model(images)\n",
                "        _, preds = torch.max(outputs, 1)\n",
                "        \n",
                "        all_preds.extend(preds.cpu().numpy())\n",
                "        all_labels.extend(labels.cpu().numpy())\n",
                "        \n",
                "# Get Class Names\n",
                "# Reverse label_map: {0: 'Name', 1: 'Name'}\n",
                "idx_to_class = {v: k for k, v in label_map.items()}\n",
                "class_names = [idx_to_class[i] for i in range(len(label_map))]\n",
                "\n",
                "cm = confusion_matrix(all_labels, all_preds)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.savefig(os.path.join(CHECKPOINT_DIR, 'confusion_matrix.png'))\n",
                "plt.show()\n",
                "\n",
                "# C. Classification Report\n",
                "print(\"\\nüìë Classification Report:\")\n",
                "print(classification_report(all_labels, all_preds, target_names=class_names))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
